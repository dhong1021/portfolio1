scale_pos_weight = df_train_pp.shape[0]  / df_train_abnormal.shape[0]

train_df, val_df = train_test_split(
    df_train_pp,
    test_size=0.3,
    stratify=df_train_pp["target"],
    shuffle=True,
    random_state=110,
)


def print_stats(df: pd.DataFrame):
    num_normal = len(df[df["target"] == 0])
    num_abnormal = len(df[df["target"] == 1])

    print(f"  Total: Normal: {num_normal}, AbNormal: {num_abnormal}" + f" ratio: {num_abnormal/num_normal}")


# Print statistics
print(f"  \tAbnormal\tNormal")
print_stats(train_df)
print_stats(val_df)

train_x = train_df.iloc[:,:-1]
train_y = train_df.iloc[:,-1]

val_x = val_df.iloc[:,:-1]
val_y = val_df.iloc[:,-1]

print(train_x.shape)
print(train_y.shape)
print(val_x.shape)
print(val_y.shape)

# Objective function for both models
def objective(trial, model_type):
    if model_type == 'xgboost':
        param = {
            'objective': 'binary:logistic',
            'eval_metric': 'error',
            'learning_rate': 0.01,
            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
            'max_depth': trial.suggest_int('max_depth', 3, 15),
            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),
            'subsample': trial.suggest_float('subsample', 0.5, 1.0),
            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),
            'scale_pos_weight': scale_pos_weight,
            'gamma': trial.suggest_float('gamma', 0.0, 5.0),
            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 100),  # L2 정규화
            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 100),    # L1 정규화
            'n_jobs': -1,
            'tree_method': 'hist',
            'random_state': 110,
            'early_stopping_rounds' : 100,
            'device': "cuda"  # GPU 사용 설정
        }
        model = XGBClassifier(**param)

        #eval_set = [(val_x, val_y)]
        model.fit(train_x, train_y, eval_set=[(val_x, val_y)], verbose=False)

    y_pred = model.predict(val_x)
    f1 = f1_score(val_y, y_pred, pos_label=1)
    return f1

# Optuna study for both models
def optimize_model(model_type):
    study = optuna.create_study(direction='maximize')
    study.optimize(lambda trial: objective(trial, model_type), n_trials=100)
    return study

# 멀티 프로세싱을 통해 두 모델을 동시에 최적화
study_xgb = optimize_model('xgboost')


# 최적의 하이퍼파라미터 및 최적 값 출력
print('XGBoost Best hyperparameters: ', study_xgb.best_params)
print('XGBoost Best F1 score: ', study_xgb.best_value)

xgb_best_params = study_xgb.best_params
# 고정된 하이퍼파라미터 정의
xgb_fixed_params = {
    'scale_pos_weight': scale_pos_weight,
    'random_state': 110,
    'objective': 'binary:logistic',
    'metric': 'error',
    'tree_method': 'hist',  # 히스토그램 기반 트리 구조 사용
    'device': "cuda",  # GPU 사용 설정
    'learning_rate': 0.01  # 고정된 학습률
#    'early_stopping_rounds' : 100
}
#교차검증시에는 early stopping이 없어야 한다

# 최적화된 하이퍼파라미터에 고정된 하이퍼파라미터 추가
xgb_best_params.update(xgb_fixed_params)

xgb_best_params

kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=110)

model = XGBClassifier(**xgb_best_params)

#print("LGBM model 상관계수 0.5이하 데이터 교차 검증 성능")

cv_result = cross_validate(model, train_x, train_y, cv=kf, scoring=['accuracy', 'precision', 'recall', 'f1'])
df_cv_result = pd.DataFrame(cv_result, columns=['test_accuracy', 'test_precision', 'test_recall', 'test_f1'])

display(df_cv_result)
display(df_cv_result.describe().loc['mean',:].to_frame().T)

eval_set = [(val_x, val_y)]

model = XGBClassifier(**xgb_best_params)
model.fit(train_x, train_y, eval_set=eval_set, verbose=False)

test_pred = model.predict(df_test_pp.iloc[:,:-1])

